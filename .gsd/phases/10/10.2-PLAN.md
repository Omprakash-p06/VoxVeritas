---
phase: 10
plan: 2
wave: 2
---

# Plan 10.2: Feature Completion (OCR & TTS)

## Objective
Finalize the missing Screen OCR feature for text-based chats and stabilize the Kokoro TTS implementation.

## Context
- src/api/qa.py
- src/services/screen_reader.py
- frontend/src/views/ChatView.tsx
- frontend/src/api/query.ts

## Tasks

<task type="auto">
  <name>Wire Screen OCR into Text Endpoints</name>
  <files>
    src/api/qa.py
    frontend/src/api/query.ts
    frontend/src/views/ChatView.tsx
  </files>
  <action>
    - Add `read_screen: bool = False` to `QARequest` and `ChatRequest` pydantic schemas.
    - Inside `ask` and `chat` routes, if `True`, call `ScreenReaderService.capture_and_read_screen()`.
    - Inject the extracted OCR text into the `prompt` (similar to `/ask_voice`).
    - Update `queryText` and `chatDirect` frontend API signatures to accept `readScreen` and pass the React state `readScreen` payload from `ChatView.tsx`.
  </action>
  <verify>Toggle "SCREEN OCR ON" in the UI, ask "What do you see on my screen?", and confirm the OCR text context is returned by the LLM.</verify>
  <done>User can successfully use Native Windows OCR alongside text-based chatting.</done>
</task>

<task type="auto">
  <name>Stabilize TTS Output Handlers</name>
  <files>
    frontend/src/views/ChatView.tsx
    src/api/voice.py
  </files>
  <action>
    - Debug why "TTS implementation is partial". 
    - Ensure `synthesizeText` in the frontend receives valid WAV forms and doesn't crash the browser audio pipeline.
    - Add detailed server-side error logging in `tts_service.py` to catch any PyTorch GPU initialization issues.
  </action>
  <verify>Toggle "TTS ON", send a query, and listen for the Kokoro TTS output reliably.</verify>
  <done>TTS reliably generates text-to-speech for all queries.</done>
</task>

## Success Criteria
- [ ] Screen reading works natively without requiring Voice Input.
- [ ] TTS generates and plays audio reliably.
