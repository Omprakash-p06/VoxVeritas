---
phase: 3
plan: 2
wave: 2
---

# Plan 3.2: Text-to-Speech (TTS) Integration

## Objective
Integrate the Kokoro TTS model to convert the LLM-generated RAG answers back into synthetic speech, completing the output layer of the pipeline.

## Context
- .gsd/SPEC.md
- .gsd/phases/3/RESEARCH.md

## Tasks

<task type="auto">
  <name>Install TTS Dependencies</name>
  <files>requirements.txt</files>
  <action>
    - Add `kokoro` and `soundfile` to `requirements.txt`.
    - Install via pip. 
  </action>
  <verify>python -c "import kokoro, soundfile; print('TTS libs OK')"</verify>
  <done>TTS libraries are successfully installed.</done>
</task>

<task type="auto">
  <name>Implement TTS Service</name>
  <files>src/services/tts_service.py</files>
  <action>
    - Create `TTSService` class using the `kokoro` library.
    - Build `generate_audio(text: str) -> str` which takes text, generates speech using a default English/multilingual voice, and saves it to `.data/temp_audio/output.wav`. 
    - Return the path to the generated audio file.
  </action>
  <verify>pytest -v tests/test_tts.py</verify>
  <done>Service can generate a `.wav` file containing spoken audio from text.</done>
</task>

<task type="auto">
  <name>Create TTS Endpoint</name>
  <files>src/api/voice.py</files>
  <action>
    - Add `POST /synthesize` endpoint that receives text and returns a `FileResponse` containing the generated `.wav` audio.
  </action>
  <verify>curl -X POST -H "Content-Type: application/json" -d '{"text": "Hello world"}' --output out.wav http://127.0.0.1:8000/synthesize</verify>
  <done>Endpoint successfully streams back valid audio files.</done>
</task>

## Success Criteria
- [ ] Kokoro installed and tested.
- [ ] `TTSService` correctly writes `.wav` files.
- [ ] `/synthesize` endpoint returns playable audio.
