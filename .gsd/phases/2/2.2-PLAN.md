---
phase: 2
plan: 2
wave: 2
---

# Plan 2.2: RAG Pipeline & Cited Answers

## Objective
Combine the Document Ingestion service (ChromaDB) with the LLM Service to form a complete RAG pipeline. Ensure that generated answers explicitly cite the source document snippets (REQ-03).

## Context
- src/services/vector_store.py
- src/services/llm_service.py
- src/api/qa.py
- .gsd/REQUIREMENTS.md

## Tasks

<task type="auto">
  <name>Enhance Vector Store for Search</name>
  <files>src/services/vector_store.py</files>
  <action>
    - Add a `query_collection(collection, query: str, n_results: int = 3) -> list[dict]` function.
    - This function should return the top match texts and their associated metadata (filename, doc_id).
  </action>
  <verify>python -c "from src.services.vector_store import get_collection, query_collection; print(query_collection(get_collection(), 'test query'))"</verify>
  <done>Function successfully queries ChromaDB and returns a structured list of results.</done>
</task>

<task type="auto">
  <name>Implement Contextual RAG Service</name>
  <files>src/services/rag_service.py</files>
  <action>
    - Create a pipeline that accepts a user query.
    - Calls `query_collection` to get context chunks.
    - Constructs a synthesized prompt for the LLM that strictly enforces returning the answer AND the exact citations (e.g., "[Source: filename.pdf]").
    - Calls `LLMService.generate_response` with this augmented prompt.
    - Return a structured schema containing `answer` and `citations`.
  </action>
  <verify>pytest -v tests/test_rag.py</verify>
  <done>Service builds an augmented prompt, queries the LLM, and formats citations successfully.</done>
</task>

<task type="auto">
  <name>Create CLI Terminal Tester</name>
  <files>tests/cli_chat.py</files>
  <action>
    - Create a Python script (`tests/cli_chat.py`) that acts as an interactive terminal interface.
    - It should allow a user to type a query, submit it to the `POST /ask` endpoint, and print the resulting answer and citations nicely to the terminal.
    - This allows full end-to-end testing without a frontend UI.
  </action>
  <verify>python tests/cli_chat.py --help</verify>
  <done>User can run the script and interact with the RAG pipeline via the terminal.</done>
</task>

## Success Criteria
- [ ] Semantic search correctly retrieves relevant chunks from ChromaDB.
- [ ] Answers are successfully generated based on retrieved context.
- [ ] The JSON response includes specific citations pointing back to the filename or chunk.
- [ ] The `cli_chat.py` script allows terminal-based interrogation of the RAG pipeline.
