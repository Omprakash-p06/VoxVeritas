import os
import soundfile as sf
import numpy as np
from loguru import logger
from kokoro import KPipeline

# Temporary directory for generated speech
TTS_AUDIO_DIR = ".data/temp_audio"
os.makedirs(TTS_AUDIO_DIR, exist_ok=True)

class TTSService:
    _instance = None
    
    def __new__(cls, lang_code="a", default_voice="af_bella"):
        if cls._instance is None:
            cls._instance = super(TTSService, cls).__new__(cls)
            cls._instance._init_service(lang_code, default_voice)
        return cls._instance

    def _init_service(self, lang_code, default_voice):
        self.lang_code = lang_code
        self.default_voice = default_voice
        self.pipeline = None
        self._load_model()

    def _load_model(self):
        logger.info(f"Loading Kokoro TTS model (lang: {self.lang_code})...")
        try:
            # Load the kokoro pipeline.
            # a=American English, b=British English. 
            self.pipeline = KPipeline(lang_code=self.lang_code)
            
            # Move the underlying PyTorch model to GPU if available
            import torch
            if torch.cuda.is_available() and hasattr(self.pipeline, 'model'):
                self.pipeline.model = self.pipeline.model.to("cuda")
                logger.info("Kokoro TTS model moved to CUDA GPU.")
            else:
                logger.info("Kokoro TTS running on CPU (no CUDA or no model attribute).")
            
            logger.info("Kokoro TTS pipeline loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load Kokoro TTS pipeline: {str(e)}")
            raise

    def generate_audio(self, text: str, voice: str = None, output_filename: str = "output.wav") -> str:
        """
        Synthesizes the given text into speech and saves it as a .wav file.
        Returns the absolute path to the generated audio file.
        """
        if not self.pipeline:
            raise RuntimeError("Kokoro pipeline is not loaded.")
            
        output_path = os.path.join(TTS_AUDIO_DIR, output_filename)
        voice_to_use = voice if voice else self.default_voice
        
        logger.debug(f"Synthesizing speech. Text length: {len(text)}, Voice: {voice_to_use}")
        
        try:
            # Generator yields (graphemes, phonemes, audio)
            generator = self.pipeline(
                text, voice=voice_to_use, speed=1.0, split_pattern=r'\n+'
            )
            
            all_audio = []
            sample_rate = 24000
            
            for i, (gs, ps, audio) in enumerate(generator):
                all_audio.append(audio)
            
            if not all_audio:
                raise ValueError("No audio was generated by the pipeline.")
                
            # Concatenate chunks if text was split
            final_audio = np.concatenate(all_audio) if len(all_audio) > 1 else all_audio[0]
            
            sf.write(output_path, final_audio, sample_rate)
            logger.debug(f"Saved synthesized audio to {output_path}")
            
            return output_path
        except Exception as e:
            logger.error(f"Error during TTS generation: {str(e)}")
            raise

def get_tts_service() -> TTSService:
    return TTSService()
